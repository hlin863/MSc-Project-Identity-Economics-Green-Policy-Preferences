{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the two sample distributions\n",
    "D1_responses = [\n",
    "    {\"do some things environmentally friendly\": 5, \"do many things environmentally friendly\": 4, \"do one or two things environmentally friendly\": 1},\n",
    "    {\"do some things environmentally friendly\": 5, \"do many things environmentally friendly\": 4, \"don't do anything environmentally friendly\": 1},\n",
    "    {\"do some things environmentally friendly\": 6, \"do many things environmentally friendly\": 4},\n",
    "    {\"do some things environmentally friendly\": 3, \"do many things environmentally friendly\": 5, \"don't do anything environmentally friendly\": 2},\n",
    "    {\"do many things environmentally friendly\": 3, \"do some things environmentally friendly\": 7},\n",
    "    {\"do some things environmentally friendly\": 5, \"do one or two things environmentally friendly\": 1, \"do many things environmentally friendly\": 4},\n",
    "    {\"do some things environmentally friendly\": 6, \"do many things environmentally friendly\": 3, \"don't do anything environmentally friendly\": 1},\n",
    "    {\"do many things environmentally friendly\": 6, \"do some things environmentally friendly\": 4},\n",
    "    {\"do many things environmentally friendly\": 6, \"do some things environmentally friendly\": 4},\n",
    "    {\"do some things environmentally friendly\": 7, \"do many things environmentally friendly\": 3},\n",
    "]\n",
    "\n",
    "# Aggregate D1 responses into a single distribution\n",
    "D1_aggregated = {\"Don't do Anything Environmentally Friendly\": 0, \"Do One or Two Things Environmentally Friendly\": 0, \"Do Some Things Environmentally Friendly\": 0, \"Do Many Things Environmentally Friendly\": 0}\n",
    "\n",
    "for response in D1_responses:\n",
    "    for key in response:\n",
    "        mapped_key = key.lower().replace(\" \", \"_\")\n",
    "        if \"do_one_or_two_things\" in mapped_key:\n",
    "            D1_aggregated[\"Do One or Two Things Environmentally Friendly\"] += response[key]\n",
    "        elif \"do_some_things\" in mapped_key:\n",
    "            D1_aggregated[\"Do Some Things Environmentally Friendly\"] += response[key]\n",
    "        elif \"do_many_things\" in mapped_key:\n",
    "            D1_aggregated[\"Do Many Things Environmentally Friendly\"] += response[key]\n",
    "        elif \"don't_do_anything\" in mapped_key:\n",
    "            D1_aggregated[\"Don't do Anything Environmentally Friendly\"] += response[key]\n",
    "\n",
    "# D2 distribution\n",
    "D2 = {\"Don't do Anything Environmentally Friendly\": 6, \"Do One or Two Things Environmentally Friendly\": 36, \"Do Some Things Environmentally Friendly\": 40, \"Do Many Things Environmentally Friendly\": 16, \"Do Everything Environmentally Friendly\": 2}\n",
    "\n",
    "# Convert both distributions to arrays in the same order\n",
    "D1_array = np.array([D1_aggregated.get(key, 0) for key in D2])\n",
    "D2_array = np.array([D2[key] for key in D2])\n",
    "\n",
    "# Calculate normalized mutual information score\n",
    "nmi_score = normalized_mutual_info_score(D1_array, D2_array)\n",
    "\n",
    "nmi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_synthetic_responses_path = 'C:\\\\Users\\\\haoch\\\\Documents\\\\COMP0190\\\\Data\\\\COMP0191-MSc-Project-Code\\\\Synthetic-Responses-JSON'\n",
    "base_data_path = 'C:\\\\Users\\\\haoch\\\\Documents\\\\COMP0190\\\\Data\\\\COMP0191-MSc-Project-Code\\\\Environmental-Views-Variables'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1_json_file = \"\\\\synthetic_responses_demo.json\"\n",
    "question_1_data_file = \"\\\\scenv_crlf\\\\Environmental Friendly Behaviour Probability Distribution Wave 10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2_json_file = \"\\\\q2_synthetic_responses.json\"\n",
    "question_2_data_file = \"\\\\scenv_bccc\\\\Scenv Bccc Probability Distribution Wave 10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_3_json_file = \"\\\\q3_synthetic_responses.json\"\n",
    "question_3_data_file = \"\\\\scenv_pmep\\\\Scenv Pmep Probability Distribution Wave 10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_4_json_file = \"\\\\q4_synthetic_responses.json\"\n",
    "question_4_data_file = \"\\\\OpenVB\\\\Open VB Probability Distribution Wave 18.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_5_json_file = \"\\\\q5_synthetic_responses.json\"\n",
    "question_5_data_file = \"\\\\scenv_meds\\\\Scenv Meds Probability Distribution Wave 10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_6_json_file = \"\\\\q6_synthetic_responses.json\"\n",
    "question_6_data_file = \"\\\\etariff\\\\etariff Probability Distribution Wave 10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_7_json_file = \"\\\\q7_synthetic_responses.json\"\n",
    "question_7_data_file = \"\\\\grimyn\\\\grimyn Probability Distribution Wave 3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_8_json_file = \"\\\\q8_synthetic_responses.json\"\n",
    "question_8_data_file = \"\\\\orga3\\\\orga3 Probability Distribution Wave 3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_9_json_file = \"\\\\q9_synthetic_responses.json\"\n",
    "question_9_data_file = \"\\\\scenv_tlat\\\\Scenv Tlat Probability Distribution Wave 10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_json_files = [question_1_json_file, question_2_json_file, question_3_json_file, question_4_json_file, question_5_json_file, question_6_json_file, question_7_json_file, question_8_json_file, question_9_json_file]\n",
    "questions_data_files = [question_1_data_file, question_2_data_file, question_3_data_file, question_4_data_file, question_5_data_file, question_6_data_file, question_7_data_file, question_8_data_file, question_9_data_file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mutual_information_value(base_data_path, data_file, base_synthetic_responses_path, json_file):\n",
    "    with open(base_data_path + data_file) as f:\n",
    "        data = json.load(f)\n",
    "    with open(base_synthetic_responses_path + json_file) as f:\n",
    "        responses = json.load(f)\n",
    "\n",
    "    # convert data keys to lower case\n",
    "    data = {k.lower(): v for k, v in data.items()}\n",
    "\n",
    "    # Aggregate synthetic responses\n",
    "    synthetic_counts = Counter()\n",
    "    for response in responses:\n",
    "        synthetic_counts.update(responses[0][\"Synthetic Responses\"])\n",
    "\n",
    "    # Convert counts to proportions\n",
    "    total_responses = sum(synthetic_counts.values())\n",
    "\n",
    "    data = {k.lower(): v * total_responses for k, v in data.items()}\n",
    "\n",
    "    synthetic_proportions = {k.lower(): v for k, v in synthetic_counts.items()} \n",
    "\n",
    "    # if the keys are \"neither agree nor disagree\", simplify the key to neither\n",
    "    if \"neither agree nor disagree\" in synthetic_proportions:\n",
    "        synthetic_proportions[\"neither\"] = synthetic_proportions[\"neither agree nor disagree\"]\n",
    "        del synthetic_proportions[\"neither agree nor disagree\"]\n",
    "\n",
    "    if \"neither agree nor disagree\" in data:\n",
    "        data[\"neither\"] = data[\"neither agree nor disagree\"]\n",
    "        del data[\"neither agree nor disagree\"]\n",
    "\n",
    "    # initialise the dictionary keys as the categories in the data\n",
    "    categories = list(data.keys())\n",
    "\n",
    "    # Ensure all keys in UKHLS data are present in synthetic data\n",
    "    for key in data.keys():\n",
    "        if key not in synthetic_proportions:\n",
    "            synthetic_proportions[key] = 0.0\n",
    "\n",
    "    data_list = [data[key] for key in categories]\n",
    "    synthetic_proportions_list = [synthetic_proportions[key] for key in categories]\n",
    "\n",
    "    print(\"Data List: \", data_list)\n",
    "    print(\"Synthetic Proportions List: \", synthetic_proportions_list)\n",
    "\n",
    "    mutual_info = normalized_mutual_info_score(data_list, synthetic_proportions_list)\n",
    "\n",
    "    print(\"Normalized Mutual Information: \", mutual_info)\n",
    "\n",
    "    return mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question  1\n",
      "Data List:  [5.744607582255893, 35.657264502394895, 40.45330745390226, 16.23203831825439, 1.9127821431925616]\n",
      "Synthetic Proportions List:  [0.0, 10, 50, 40, 0.0]\n",
      "Normalized Mutual Information:  0.9057460992755193\n",
      "\n",
      "\n",
      "Question  2\n",
      "Data List:  [9.13, 36.75, 33.910000000000004, 16.86, 2.5100000000000002]\n",
      "Synthetic Proportions List:  [3, 13, 42, 32, 10]\n",
      "Normalized Mutual Information:  1.0\n",
      "\n",
      "\n",
      "Question  3\n",
      "Data List:  [6.801, 38.421, 19.078999999999997, 4.532, 31.061]\n",
      "Synthetic Proportions List:  [47, 32, 11, 8, 2]\n",
      "Normalized Mutual Information:  1.0\n",
      "\n",
      "\n",
      "Question  4\n",
      "Data List:  [5.0, 45.0, 28.000000000000004, 2.0, 20.0]\n",
      "Synthetic Proportions List:  [56, 2, 31, 9, 2]\n",
      "Normalized Mutual Information:  0.9057460992755193\n",
      "\n",
      "\n",
      "Question  5\n",
      "Data List:  [18.34474992962372, 40.56801476337931, 29.983422476619438, 8.720402865096494, 2.383409965281036]\n",
      "Synthetic Proportions List:  [5, 13, 30, 38, 14]\n",
      "Normalized Mutual Information:  1.0\n",
      "\n",
      "\n",
      "Question  6\n",
      "Data List:  [8.778179794043975, 7.854160868355136, 81.34149735596993, 2.026161981630949]\n",
      "Synthetic Proportions List:  [15, 57, 28, 0.0]\n",
      "Normalized Mutual Information:  1.0\n",
      "\n",
      "\n",
      "Question  7\n",
      "Data List:  [11.26165185345762, 88.73834814654238]\n",
      "Synthetic Proportions List:  [69, 31]\n",
      "Normalized Mutual Information:  1.0\n",
      "\n",
      "\n",
      "Question  8\n",
      "Data List:  [1.747693399574166, 98.25230660042583]\n",
      "Synthetic Proportions List:  [52, 48]\n",
      "Normalized Mutual Information:  1.0\n",
      "\n",
      "\n",
      "Question  9\n",
      "Data List:  [2.3180879684664957, 11.699931176875431, 32.59713445535882, 39.20102609022086, 14.183820309078396]\n",
      "Synthetic Proportions List:  [0.0, 4, 31, 43, 22]\n",
      "Normalized Mutual Information:  1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mutual_info_scores = []\n",
    "for i in range(len(questions_json_files)):\n",
    "    print(\"Question \", i+1)\n",
    "    temp_score = calculate_mutual_information_value(base_data_path, questions_data_files[i], base_synthetic_responses_path, questions_json_files[i])\n",
    "    print(\"\\n\")\n",
    "    mutual_info_scores.append(temp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the temp scores and their question number in a text file in the same directory\n",
    "with open(\"mutual_info_scores.txt\", \"w\") as f:\n",
    "    for i in range(len(mutual_info_scores)):\n",
    "        # round each score to 4 decimal places\n",
    "        f.write(\"Question \" + str(i+1) + \": \" + str(round(mutual_info_scores[i], 4)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study 2: Hypothesis 1 - Difference in Attitudes to Environmental Issues by whether an individual has children. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_with_children_json_paths = [\"\\\\Hypothesis-1\\\\synthetic_responses_question_1_wave_1_with_children.json\", \"\\\\Hypothesis-1\\\\synthetic_responses_question_1_wave_5_with_children.json\", \"\\\\Hypothesis-1\\\\synthetic_responses_question_1_wave_10_with_children.json\"]\n",
    "q1_without_children_json_paths = [\"\\\\Hypothesis-1\\\\synthetic_responses_question_1_wave_1_without_children.json\", \"\\\\Hypothesis-1\\\\synthetic_responses_question_1_wave_5_without_children.json\", \"\\\\Hypothesis-1\\\\synthetic_responses_question_1_wave_10_without_children.json\"]\n",
    "wave_numbers = [1, 5, 10]\n",
    "\n",
    "q1_with_children_json_filepath = \"\\\\Hypothesis-1\\\\synthetic_responses_question_1_wave_10_with_children.json\"\n",
    "q1_without_children_json_filepath = \"\\\\Hypothesis-1\\\\synthetic_responses_question_1_wave_10_without_children.json\"\n",
    "question_one_responses = [\"Don't do Anything Environmentally Friendly\", \"Do One or Two Things Environmentally Friendly\", \"Do Some Things Environmentally Friendly\", \"Do Many Things Environmentally Friendly\", \"Do Everything Environmentally Friendly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mutual_information_value_h1(base_data_path, d1_file, d2_file, pot_responses):\n",
    "    with open(base_data_path + d1_file) as f:\n",
    "        d1 = json.load(f)\n",
    "    with open(base_synthetic_responses_path + d2_file) as f:\n",
    "        d2 = json.load(f)\n",
    "\n",
    "    # convert data keys to lower case\n",
    "    d1 = {k.lower(): v for k, v in d1.items()}\n",
    "\n",
    "    d2 = {k.lower(): v for k, v in d2.items()}\n",
    "\n",
    "    pot_responses = [response.lower() for response in pot_responses]\n",
    "\n",
    "    for response in pot_responses:\n",
    "        if response not in d1.keys():\n",
    "            d1[response] = 0\n",
    "\n",
    "        if response not in d2.keys():\n",
    "            d2[response] = 0\n",
    "\n",
    "    d1_list = [d1[key] for key in pot_responses]\n",
    "    d2_list = [d2[key] for key in pot_responses]\n",
    "\n",
    "    mutual_info = normalized_mutual_info_score(d1_list, d2_list)\n",
    "\n",
    "    return mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 Wave  1\n",
      "Mutual Information Score:  0.9057460992755193\n",
      "\n",
      "\n",
      "Question 1 Wave  5\n",
      "Mutual Information Score:  0.9057460992755193\n",
      "\n",
      "\n",
      "Question 1 Wave  10\n",
      "Mutual Information Score:  1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(q1_with_children_json_paths)):\n",
    "    print(\"Question 1 Wave \", wave_numbers[i])\n",
    "    temp_score = calculate_mutual_information_value_h1(base_data_path, question_1_data_file, q1_with_children_json_paths[i], question_one_responses)\n",
    "    print(\"Mutual Information Score: \", temp_score)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_wave_10_mi = calculate_mutual_information_value_h1(base_synthetic_responses_path, q1_with_children_json_filepath, q1_without_children_json_filepath, question_one_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 Wave 10 Mutual Information:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 1 Wave 10 Mutual Information: \", q1_wave_10_mi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
